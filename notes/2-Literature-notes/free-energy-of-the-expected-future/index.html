<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="to act adaptively, ==agents should act so as to minimize the difference between what they predict will happen, and what they desire to happen==."><title>free energy of the expected future</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://notes.adanielnoel.com//icon.png><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Source+Sans+Pro:wght@400;600;700&family=Fira+Code:wght@400;700&display=swap" rel=stylesheet><link href=https://notes.adanielnoel.com/styles.8010c0d8fb32a34f00886b05df3d230c.min.css rel=stylesheet><script src=https://notes.adanielnoel.com/js/darkmode.46b07878b7f5d9e26ad7a3c40f8a0605.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script src=https://notes.adanielnoel.com/js/popover.688c5dcb89a57776d7f1cbeaf6f7c44b.min.js></script>
<script>const BASE_URL="https://notes.adanielnoel.com/",fetchData=Promise.all([fetch("https://notes.adanielnoel.com/indices/linkIndex.a7b76ec00a8588f3b12833e4d7d97fff.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://notes.adanielnoel.com/indices/contentIndex.084a0e9adf04223e79ad1ea484e70f76.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const n=new URL("https://notes.adanielnoel.com/"),s=n.pathname,o=window.location.pathname,i=s==o,e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=i&&!1;drawGraph("https://notes.adanielnoel.com",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2}),initPopover("https://notes.adanielnoel.com",!0,!0)},init=(e=document)=>{renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})}</script><script>window.Million={navigate:e=>window.location.href=e,prefetch:()=>{}},init(),render()</script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-WM9E85JH9W"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-WM9E85JH9W",{anonymize_ip:!1})}</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://notes.adanielnoel.com/js/search.cf33b507388f3dfd5513a2afcda7af41.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://notes.adanielnoel.com/>ðŸª´ Ale's digital garden</a></h1><svg tabindex="0" id="search-icon" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg><div class=spacer></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>free energy of the expected future</h1><p class=meta>Last updated June 27, 2022</p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#definitions>Definitions</a><ol><li><a href=#distributions-and-symbols>Distributions and symbols</a></li><li><a href=#expected-free-energy>Expected free energy</a></li><li><a href=#free-energy-of-the-future>Free Energy of the Future</a></li></ol></li></ol></nav></details></aside><blockquote><p>to act adaptively, ==agents should act so as to minimize the difference between what they predict will happen, and what they desire to happen==. Put another way, adaptive action for an agent consists of forcing reality to unfold according to itsâ€™ preferences. â€”
<a href=/notes/6-Citation-notes/Millidge2020c/ rel=noopener class=internal-link data-src=/notes/6-Citation-notes/Millidge2020c/>@Millidge2020c</a></p></blockquote><p>$$
\begin{aligned}
\mathbf{F E E F}(\pi)<em>{\tau}
&= \mathbb{E}</em>{Q\left(o_{\tau}, x_{\tau} \mid \pi\right)}\mathbf{D}<em>{K L}\left[Q\left(o</em>{\tau}, x_{\tau} \mid \pi\right)|\ln \tilde{p}\left(o_{\tau}, x_{\tau}\right)\right] \\&=\mathbb{E}<em>{Q\left(o</em>{\tau}, x_{\tau} \mid \pi\right)}\left[\ln Q\left(o_{\tau}, x_{\tau} \mid \pi\right)-\ln \tilde{p}\left(o_{\tau}, x_{\tau}\right)\right] \\&=\underbrace{\mathbb{E}<em>{Q\left(x</em>{\tau} \mid \pi\right)} \mathbf{D}<em>{K L}\left[Q\left(o</em>{\tau} \mid x_{\tau}\right) | \tilde{p}\left(o_{\tau}\right)\right]}<em>{\text {Extrinsic Value }}-\underbrace{\mathbb{E}</em>{Q\left(o_{\tau} \mid \pi\right)} \mathbf{D}<em>{K L}\left[Q\left(x</em>{\tau} \mid o_{\tau}\right) | Q\left(x_{\tau} \mid \pi\right)\right]}_{\text {Intrinsic Value }}
\end{aligned}
$$</p><blockquote><p>The first thing to note is that <em>the intrinsic value terms of the FEEF and the EFE are identical</em> (see
<a rel=noopener class="internal-link broken" data-src=notes/2-Literature-notes/free-energy-of-the-expected-future.md/#Definitions>Definitions</a> below), under the assumption that the variational posterior is approximately correct $Q(x_\tau\mid o_\tau) \approx p(x_\tau\mid o_\tau)$ such that <em>FEEF-minimizing agents will necessarily show identical epistemic behavior to EFE-minimizing agents</em>. Unlike the EFE, however, the FEEF also possesses a strong naturalistic grounding as a bound on a theoretically relevant quantity. ==The FEEF can maintain both its information-maximizing imperative and its theoretical grounding since it is derived from the minimization of a KL divergence rather than the maximization of a log model evidence==. â€”
<a href=/notes/6-Citation-notes/Millidge2020c/ rel=noopener class=internal-link data-src=/notes/6-Citation-notes/Millidge2020c/>@Millidge2020c</a></p></blockquote><blockquote><p>The key difference with the EFE lies in the likelihood term. ==While the EFE simply tries to maximize the expected evidence of the desired observations, the FEEF minimizes the KL divergence between the likelihood of observations predicted under the veridical generative model and the marginal likelihood of observations under the biased generative model==.
[&mldr;] The extrinsic value term thus encourages the agent to choose its actions such that its predictions over states lead to observations which are close to its preferred observations, while also trying move to states whereby the entropy over observations is maximized, thus leading the agent to move towards states where the generative model is not as certain about the likely outcome. ==In effect, the FEEF possesses another exploratory term, in addition to the information gain, which the EFE lacks==. â€”
<a href=/notes/6-Citation-notes/Millidge2020c/ rel=noopener class=internal-link data-src=/notes/6-Citation-notes/Millidge2020c/>@Millidge2020c</a></p></blockquote><blockquote><p>Another important advantage is that ==the FEEF it is mathematically equivalent to the VFE (with a biased generative model) in the present time with a current observation==. [&mldr;] This means that theoretically we can consider an agent to be both inferring and planning using the same objective, which is not true of the EFE. <em>The EFE does not reduce to the VFE when observations are known, and thus requires a separate objective function to be minimized for planning compared to inference</em>. Because of this, it is actually possible to argue that FEEF is mandated by the free-energy principle. ==On this view there is no distinction between present and future inference and both follow from minimizing the same objective but under different informational constraints==. â€”
<a href=/notes/6-Citation-notes/Millidge2020c/ rel=noopener class=internal-link data-src=/notes/6-Citation-notes/Millidge2020c/>@Millidge2020c</a></p></blockquote><hr><a href=#definitions><h2 id=definitions><span class=hanchor arialabel=Anchor># </span>Definitions</h2></a><p><strong>VFE</strong> : <em>Instantaneous Free energy</em>
$$
\begin{aligned}
\mathbb{F} &=\mathbf{D}<em>{K L}\left[Q\left(x</em>{t} \mid o_{t} ; \phi\right) | p\left(o_{t}, x_{t}\right)\right] \\&=\mathbb{E}<em>{Q\left(x</em>{t} \mid o_{t} ; \phi\right)}\left[\ln \frac{Q\left(x_{t} \mid o_{t} ; \phi\right)}{p\left(o_{t}, x_{t}\right)}\right] \\&=-\underbrace{\mathbb{E}<em>{Q\left(x</em>{t} \mid o_{t} ; \phi\right)}\left[\ln p\left(o_{t} \mid x_{t}\right)\right]}<em>{\text {Accuracy }}+\underbrace{\mathbf{D}</em>{K L}\left[Q\left(x_{t} \mid o_{t} ; \phi\right)|| p\left(x_{t}\right)\right]}_{\text {Complexity }}
\end{aligned}
$$
<strong>EFE</strong>: <em>Expected free energy</em>
<strong>AIF</strong>: <em>Active inference</em>. Agents choose policies that minimize a free energy functional (originally a cumulative sum over time of EFE
<a href=/notes/6-Citation-notes/Friston2015d/ rel=noopener class=internal-link data-src=/notes/6-Citation-notes/Friston2015d/>@Friston2015d</a>). Active inference revolves around the idea of action-conditioned futures.</p><p>==Note==: in the intro it makes a very complete bibliographical overview of applications of AIF in different areas.</p><p>Newly proposed free energy functionals:
<strong>FEF</strong>: <em>Free Energy of the Future.</em>
<strong>FEEF</strong>: <em>Free Energy of the Expected Future</em></p><a href=#distributions-and-symbols><h3 id=distributions-and-symbols><span class=hanchor arialabel=Anchor># </span>Distributions and symbols</h3></a><p>$t$: time-step in the past
$\tau$: time-step in the future ($t&lt;\tau$)
$T$: time horizon, so that $\tau&lt;T$
$o_t$: observed states or observations
$x_t$: hidden states
$a_\tau$: action
$\pi=[a_1, a_2,\dots,a_T]$: policy
$Q(x_t\mid o_t ;\phi)$: variational posterior; approximate posterior density parametrized by $\psi$
$Q(x_t)=\mathbb{E}<em>{p(x_t\mid x</em>{t-1})}[Q(x_{t-1}\mid o_{t-1};\psi)]$: Variational prior; obtained by mapping the previous posterior through the transition dynamics.
$p(x_t\mid x_{t-1})$: true transition dynamics
$\tilde{p}(o_{\tau:T})$: Biased observation model; encodes an agent&rsquo;s goals.
$\tilde{p}(o_\tau,x_\tau)\approx\tilde{p}(o_\tau)Q(x_\tau\mid o_\tau)$: Biased generative model of the world.</p><hr><a href=#expected-free-energy><h3 id=expected-free-energy><span class=hanchor arialabel=Anchor># </span>Expected free energy</h3></a><p><strong>Planning as inference of future states</strong></p><blockquote><p>Instead of saying: I have some goal, what do I have to do to achieve it? the active inference agent asks: <em>Given that my goals were achieved, what would have been the most probable actions that I took?</em></p></blockquote><p><strong>Expected free energy</strong></p><blockquote><p>In the active inference framework, <em>the goal is to infer a variational distribution over both hidden states and policies that maximally fit to a biased generative model of the future</em>. The framework defines the variational objective function to be minimized, the Expected Free Energy, from time $\tau$ until the time horizon $T$, which is denoted $\mathcal{G}$:
$$
\begin{aligned}
\mathcal{G}(\pi) &=\mathbb{E}<em>{Q\left(o</em>{\tau}, x_{\tau} \mid \pi\right)}\left[\ln Q\left(x_{\tau} \mid \pi\right)-\ln \tilde{p}\left(o_{\tau}, x_{\tau}\right)\right] \\&=\mathbb{E}<em>{Q\left(o</em>{\tau}, x_{\tau} \mid \pi\right)}\left[\ln Q\left(x_{\tau} \mid \pi\right)-\ln \tilde{p}\left(o_{\tau} \mid x_{\tau}\right)-\ln p\left(x_{\tau}\right)\right] \\&=\underbrace{-\mathbb{E}<em>{Q\left(o</em>{\tau}, x_{\tau} \mid \pi\right)}\left[\ln \tilde{p}\left(o_{\tau} \mid x_{\tau}\right)\right]}<em>{\text {Accuracy }}+\underbrace{\mathbb{E}</em>{Q\left(o_{\tau} \mid x_{\tau}\right)}\left[\mathbf{D}<em>{K L}\left[Q\left(x</em>{\tau} \mid \pi\right) | p\left(x_{\tau}\right)\right]\right]}<em>{\text {Complexity }} \\&= \underbrace{-\mathbb{E}</em>{Q\left(o_{\tau}, x_{\tau} \mid \pi\right)}\left[\ln \tilde{p}\left(o_{\tau}\right)\right]}<em>{\text {Extrinsic Value }}-\underbrace{\mathbb{E}</em>{Q\left(o_{\tau} \mid \pi\right)}\left[\mathbf{D}<em>{K L}\left[Q\left(x</em>{\tau} \mid o_{\tau}\right) | Q\left(x_{\tau} \mid \pi\right)\right]\right]}_{\text {Epistemic Value }}
\end{aligned}
$$</p></blockquote><hr><a href=#free-energy-of-the-future><h3 id=free-energy-of-the-future><span class=hanchor arialabel=Anchor># </span>Free Energy of the Future</h3></a><p><strong>Requirements for a free energy functional for an active inference agent</strong></p><blockquote><p>We argue that the natural extension of the free energy into the future must possess direct analogs to the two crucial properties of the VFE: <em>it must be expressible as a KL-divergence between a posterior and a generative model</em>, such that minimizing it causes the variational density to better approximate the true posterior. <em>Secondly, it must also bound the log model evidence of future observations</em>.</p></blockquote><p><strong>Importance of the second requirement</strong></p><blockquote><p>Bounding the log model evidence (or surprisal) is vital since the surprisal is the core quantity which, under the FEP, all systems are driven to minimize. If the VFE extended into the future failed to bound the surprisal, then minimizing this extension would not necessarily minimize surprisal, and thus <em>any agent which minimized such an extension would be in violation of the FEP</em>.</p></blockquote><p><strong>Free Energy of the Future</strong>
$$
\begin{aligned}
\mathbf{F E F}<em>{\tau}(\pi) &=\mathbb{E}</em>{Q\left(o_{\tau} \mid \pi\right)}\left[\ln Q(x_\tau\mid o_\tau)-\ln\tilde{p}(o_\tau,x_\tau)\right] \\&=\mathbb{E}<em>{Q\left(o</em>{\tau} \mid \pi\right)}\mathbf{D}<em>{K L}\left[Q\left(x</em>{\tau} \mid o_{\tau}\right) | \tilde{p}\left(o_{\tau}, x_{\tau}\right)\right] \\& \approx-\underbrace{\mathbb{E}<em>{Q\left(o</em>{\tau}, x_{\tau} \mid \pi\right)}\left[\ln \tilde{p}\left(o_{\tau} \mid x_{\tau}\right)\right]}<em>{\text {Accuracy }}+\underbrace{\mathbb{E}</em>{Q\left(o_{\tau} \mid \pi\right)} \mathbf{D}<em>{K L}\left[Q\left(x</em>{\tau} \mid o_{\tau}\right) | Q\left(x_{\tau} \mid \pi\right)\right]}_{\text {Complexity }}
\end{aligned}
$$</p><blockquote><p>Unlike the EFE however, the expected information gain (complexity) term is positive while in the EFE term it is negative. [&mldr;] An <em>FEF agent thus tries to maximize its reward while trying to explore as little as possible</em>. While this sounds surprising, <em>it is in fact directly analogous to the complexity term in the VFE</em>, which mandates maximizing the likelihood of an observation, while also keeping the posterior as close as possible to the prior.</p></blockquote><p><strong>FEF is an upper bound to surprise</strong>
$$
-\mathbb{E}<em>{Q\left(o</em>{\tau} \mid \pi\right)}\left[\ln\tilde{p}(o_\tau)\right] \leq \mathbb{E}<em>{Q\left(o</em>{\tau} \mid \pi\right)}\mathbf{D}<em>{K L}\left[Q\left(x</em>{\tau} \mid o_{\tau}\right) | \tilde{p}\left(o_{\tau}, x_{\tau}\right)\right] = \mathbf{F E F}_{\tau}(\pi)
$$
FEF is an upper bound on expected model evidence, which can be tightened by minimizing the FEF. By contrast, the EFE is a lower bound which must be maximized.</p></article><hr><div class=page-end><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://notes.adanielnoel.com/js/graph.afdb02e537635f9a611b53a988e5645b.js></script></div></div><div id=contact_buttons><footer><p>Made by Alejandro Daniel Noel using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2022</p><ul><li><a href=/>Home</a></li><li><a href=https://twitter.com/adanielnoel>Twitter</a></li><li><a href=https://github.com/adanielnoel>Github</a></li></ul></footer></div></div></body></html>